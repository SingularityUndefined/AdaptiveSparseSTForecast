{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1592ce95",
   "metadata": {},
   "source": [
    "# Demo for Connectivity Optimization with Undirected Graph\n",
    "\n",
    "## 1 Experimental Setup\n",
    "\n",
    "Predefined graph: 6-nodes, sparse connection with edge weights 0.6\n",
    "\n",
    "Data generalization according to GRMF: given $\\mathbf{y}|\\mathbf{x},\\mathbf{L}\\sim \\mathcal{N}(\\mathbf{x},\\sigma^2\\mathbf{I}), \\mathbf{x}|\\mathbf{L}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{L}^\\dagger)$, generate $\\mathbf{y}|\\mathbf{L}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^2\\mathbf{I}+\\mathbf{L}^\\dagger)$\n",
    "\n",
    "Data number in total: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# Graph design\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_graph_from_adj(adj, title=None):\n",
    "    G = nx.from_numpy_array(adj.numpy())\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray')\n",
    "    edge_labels = {(u, v): f'{d[\"weight\"]:.1f}' for (u, v, d) in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def generate_graph_from_edges(num_nodes, edges, weights=None):\n",
    "    if weights is None:\n",
    "        weights = torch.ones(len(edges))\n",
    "    adj = torch.zeros((num_nodes, num_nodes))\n",
    "    adj[edges[:, 0], edges[:, 1]] = weights\n",
    "    adj = adj + adj.t()  # make it symmetric\n",
    "    adj.fill_diagonal_(0)  # remove self-loops\n",
    "    \n",
    "    # For visualization only (using scipy sparse)\n",
    "    draw_graph_from_adj(adj)\n",
    "    \n",
    "    return adj\n",
    "\n",
    "def generate_y(num_nodes, sigma, L, n):\n",
    "    # Convert L to tensor if it's not already\n",
    "    L = torch.tensor(L, dtype=torch.float32)\n",
    "    \n",
    "    cov = sigma**2 * torch.eye(num_nodes) + torch.pinverse(L)\n",
    "    # For generating multivariate normal, we need to make sure covariance is symmetric\n",
    "    cov = (cov + cov.t()) / 2\n",
    "    \n",
    "    # Generate multivariate normal samples\n",
    "    y = torch.distributions.MultivariateNormal(\n",
    "        loc=torch.zeros(num_nodes),\n",
    "        covariance_matrix=cov\n",
    "    ).sample((n,))\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c67518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2       -0.6       -0.6       -0.        -0.        -0.       ]\n",
      " [-0.6        1.2       -0.6       -0.        -0.        -0.       ]\n",
      " [-0.6       -0.6        1.8000001 -0.6       -0.        -0.       ]\n",
      " [-0.        -0.        -0.6        1.8000001 -0.6       -0.6      ]\n",
      " [-0.        -0.        -0.        -0.6        1.2       -0.6      ]\n",
      " [-0.        -0.        -0.        -0.6       -0.6        1.2      ]]\n"
     ]
    }
   ],
   "source": [
    "edges = [[0,1],[0,2],[1,2],[2,3],[3,4],[4,5],[3,5]]\n",
    "edges = torch.tensor(edges)\n",
    "weights = torch.tensor([0.6]*len(edges))\n",
    "num_nodes = 6\n",
    "adj = generate_graph_from_edges(num_nodes, edges, weights)\n",
    "L = laplacian(adj, normed=False)\n",
    "print(L)\n",
    "# generate data\n",
    "sigma = 0.1\n",
    "mu = sigma ** 2\n",
    "n = 128\n",
    "y = generate_y(num_nodes, sigma, L, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78c96f",
   "metadata": {},
   "source": [
    "## 2 Graph Learning Module (Simple)\n",
    "\n",
    "- Define a *learnable* embedding for each node, the embedded signals $\\tilde{\\mathbf{x}}_i = [x_i;\\mathbf{e}_i]$\n",
    "- Feature extraction: A single linear layer with activation `LeakyReLU(0.2)`: $\\mathbf{f}_i = \\sigma(\\mathbf{H}\\tilde{\\mathbf{x}}_i+\\mathbf{h})$\n",
    "- Weight calculation: $w_{i,j}=\\alpha\\exp(-\\Vert \\mathbf{f}_i - \\mathbf{f}_j \\Vert_2^2)$\n",
    "- Laplacian matrix: $\\mathbf{L}=\\text{diag}(\\mathbf{W1})-\\mathbf{W}$\n",
    "\n",
    "Parameters: $\\Theta=(\\{\\mathbf{e}_i\\}_{i=1}^{N}, \\mathbf{H},\\mathbf{h})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c35caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj before scaling tensor([[0.0000, 0.4646, 0.4044, 0.5639, 0.4095, 0.5282],\n",
      "        [0.4646, 0.0000, 0.5858, 0.5224, 0.6635, 0.4352],\n",
      "        [0.4044, 0.5858, 0.0000, 0.5380, 0.6108, 0.4330],\n",
      "        [0.5639, 0.5224, 0.5380, 0.0000, 0.4994, 0.5809],\n",
      "        [0.4095, 0.6635, 0.6108, 0.4994, 0.0000, 0.4148],\n",
      "        [0.5282, 0.4352, 0.4330, 0.5809, 0.4148, 0.0000]],\n",
      "       grad_fn=<CopySlices>) tensor(7.9975, grad_fn=<PowBackward0>) 1.0\n",
      "current norm tensor(2.8280, grad_fn=<CopyBackwards>)\n",
      "scale tensor(1.0003, grad_fn=<MulBackward0>)\n",
      "tensor(1.0003, grad_fn=<MulBackward0>)\n",
      "Learned adjacency matrix:\n",
      "tensor([[0.0000, 0.4648, 0.4046, 0.5641, 0.4097, 0.5283],\n",
      "        [0.4648, 0.0000, 0.5860, 0.5225, 0.6637, 0.4354],\n",
      "        [0.4046, 0.5860, 0.0000, 0.5382, 0.6110, 0.4332],\n",
      "        [0.5641, 0.5225, 0.5382, 0.0000, 0.4996, 0.5811],\n",
      "        [0.4097, 0.6637, 0.6110, 0.4996, 0.0000, 0.4150],\n",
      "        [0.5283, 0.4354, 0.4332, 0.5811, 0.4150, 0.0000]],\n",
      "       grad_fn=<MulBackward0>) tensor(8.0025, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class GraphLearningModule(nn.Module):\n",
    "    # generate weight matrix from node embeddings\n",
    "    def __init__(self, num_nodes, emb_dim=6, feature_dim=3, alpha=1.0, c=8):\n",
    "        super(GraphLearningModule, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        # embedding vectors\n",
    "        self.node_embeddings = nn.Parameter(torch.randn(num_nodes, emb_dim))  # emb_dim-dimensional embeddings\n",
    "        self.fc = nn.Linear(emb_dim, feature_dim)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        # self.alpha = alpha # scaling factor by calculation\n",
    "        self.c = c\n",
    "\n",
    "    # def scale_alpha(self, adj):\n",
    "    #     # scale alpha such that norm(alpha * adj) = c\n",
    "    #     current_norm = torch.norm(self.alpha * adj)\n",
    "    #     print('current norm', current_norm)\n",
    "    #     scaling_factor = self.c / current_norm**2 if current_norm != 0 else 1\n",
    "    #     self.alpha *= scaling_factor\n",
    "    #     return scaling_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, num_nodes)\n",
    "        B = x.size(0)\n",
    "        # embed each node\n",
    "        # Expand node_embeddings to batch dimension and add directly to x\n",
    "        e = x.unsqueeze(-1) + self.node_embeddings.unsqueeze(0) # in shape (B, N, emb_dim)\n",
    "        f = self.leakyrelu(self.fc(e)) # in shape (B, N, feature_dim)\n",
    "        df = f.unsqueeze(2) - f.unsqueeze(1) # in shape (B, N, N, feature_dim)\n",
    "        # dis = torch.norm(df, dim=-1)\n",
    "        adj = self.alpha * torch.exp(-(df**2).sum(-1)).mean(0) # in shape (N, N)\n",
    "        adj.fill_diagonal_(0)\n",
    "        # print('adj before scaling', adj, adj.norm()**2, self.alpha)\n",
    "        # scaling_factor = self.scale_alpha(adj)\n",
    "        # print('scale', scaling_factor)\n",
    "        # adj = adj * scaling_factor\n",
    "        # print(self.alpha)\n",
    "        return adj\n",
    "    \n",
    "glm = GraphLearningModule(num_nodes)\n",
    "adj_learned = glm(y)\n",
    "print(\"Learned adjacency matrix:\")\n",
    "print(adj_learned, adj_learned.norm()**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f4917",
   "metadata": {},
   "source": [
    "## 3 GEM Algorithm\n",
    "### 3.1 Hard E-step: Update $\\mathbf{x}$\n",
    "$$\n",
    "\\min_x \\Vert \\mathbf{y}-\\mathbf{x}\\Vert_2^2 + \\mu \\mathbf{x}^\\top\\mathbf{Lx}\\\\\n",
    "\\mathbf{x}^*=(\\mathbf{I}+\\mu\\mathbf{L})^{-1}\\mathbf{y}\n",
    "$$\n",
    "In practice, solve in CG\n",
    "\n",
    "Update graph with new $\\mathbf{x}$ and project it to the sphere\n",
    "### 3.2 M-step-1: update graph weights $\\Theta$\n",
    "$$\n",
    "\\min_\\Theta \\mathbf{x}^\\top\\mathbf{Lx} \\quad \\text{s.t. }~ \\Vert \\mathbf{W}\\circ\\mathbf{S} \\Vert_2^2=c\n",
    "$$\n",
    "Projected Gradient Method:\n",
    "1. Gradient step: $\\Theta^{t+1} = \\Theta^{t} - \\delta^{t}\\nabla_\\Theta(\\mathbf{x}^\\top\\mathbf{L^tx})$\n",
    "2. Recompute graph: $\\mathbf{W}^{t+1} = \\mathbf{W}(\\Theta^{t+1})$\n",
    "3. Project to the sphere: $\\alpha \\leftarrow \\frac{\\sqrt{c}}{\\Vert \\mathbf{W}^{t+1} \\Vert_F} \\alpha$\n",
    "### 3.3 M-step-2 update graph connectivity $\\mathbf{S}$\n",
    "$$\n",
    "\\min_{\\mathbf{S}\\in\\{0,1\\}^{N\\times N}} \\mathbf{x}^\\top\\mathbf{Lx} + \\gamma \\Vert \\mathbf{S}\\Vert_{0,\\text{off}}\n",
    "$$\n",
    "Greedy approach:\n",
    "1. Sort $Q_{i,j} = \\frac{1}{2W_{i,j}}(x_i-x_j)^2+\\frac{\\gamma}{W_{i,j}^2}$ in ascending order $\\iff$ Sort $Q'_{i,j}=W_{i,j}^2 / [\\frac{1}{2}W_{i,j}(x_i-x_j)^2 + \\gamma]$ in descending order (to avoid division by zeros)\n",
    "2. Select edges according to ascending $Q$ until reaches $\\Vert\\mathbf{W}\\Vert_F^2=c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Laplacian_from_adj(adj):\n",
    "    D = torch.diag(adj.sum(1))\n",
    "    L = D - adj\n",
    "    return L\n",
    "\n",
    "def GLR(x, L):\n",
    "    # x in shape (B, N), L in shape (N, N)\n",
    "    # return torch.trace(x @ L @ x.t()) / x.size(0) # in shape (B, N)\n",
    "    return torch.trace(x.t() @ L @ x) / x.size(0) # in shape (B, N)\n",
    "\n",
    "class GEM(nn.Module):\n",
    "    def __init__(self, num_nodes, mu, gamma, step_size, emb_dim=6, feature_dim=3, alpha=1.0, c=8):\n",
    "        super(GEM, self).__init__()\n",
    "        self.glm = GraphLearningModule(num_nodes, emb_dim, feature_dim, alpha, c)\n",
    "        # self.S = torch.ones((num_nodes, num_nodes)) - torch.eye(num_nodes)  # all-one matrix with zero diagonal\n",
    "        self.mu = mu\n",
    "        self.alpha = alpha\n",
    "        self.c = c\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def scale_W(self, adj, S):\n",
    "        W = adj * S\n",
    "        return math.sqrt(self.c) * W / W.norm() if W.norm() != 0 else W\n",
    "    \n",
    "    def E_step(self, y, W):\n",
    "        # y in (B, N)\n",
    "        B = y.size(0)\n",
    "        D = torch.diag(W.sum(1))\n",
    "        L = D - W\n",
    "        cov = torch.eye(self.glm.num_nodes) + self.mu * L\n",
    "        return torch.linalg.solve(cov, y.t()).t()  # return in shape (B, N)\n",
    "    \n",
    "    def M_step_1(self, x, L):\n",
    "        loss = GLR(x, L)\n",
    "        # backward to gradient descent\n",
    "        grads = torch.autograd.grad(loss, self.glm.parameters(), retain_graph=True, create_graph=True)\n",
    "        with torch.no_grad():\n",
    "            for param, grad in zip(self.glm.parameters(), grads):\n",
    "                param.sub_(self.step_size * grad)\n",
    "        # if use meta-learning in unrolling model, needs further treatment\n",
    "        return None\n",
    "    \n",
    "    def M_step_2(self, x, W):\n",
    "        # optimize alpha with gradient descent\n",
    "        dis_x = x.unsqueeze(2) - x.unsqueeze(1) # in shape (B, N, N)\n",
    "        dis_x_2 = (dis_x**2).mean(0) # in shape (N, N)\n",
    "        # calculate Q_inv and sort in an descending order\n",
    "        Q = W ** 2 / (dis_x_2 * W / 2 + self.gamma)  # in shape (N, N)\n",
    "        Q_sorted, Q_indices = torch.sort(Q.view(-1), descending=True)\n",
    "        # select edges until norm(W*S) <= c\n",
    "        W_flatten = W.view(-1)\n",
    "        S_flatten = torch.zeros_like(Q).view(-1)\n",
    "        sum_squared_W = 0\n",
    "        idx = 0\n",
    "        while sum_squared_W < self.c and idx < len(Q_sorted):\n",
    "            current_idx = Q_indices[idx]\n",
    "            S_flatten[current_idx] = 1\n",
    "            sum_squared_W += W_flatten[current_idx] ** 2\n",
    "            idx += 1\n",
    "        S = S_flatten.view(self.glm.num_nodes, self.glm.num_nodes)\n",
    "        S = ((S + S.t()) > 0).float() # make symmetric\n",
    "        S.fill_diagonal_(0)  # remove self-loops\n",
    "        return S\n",
    "    # needs to be further simplified to be more efficient\n",
    "\n",
    "\n",
    "    def single_step(self, y, adj, S):\n",
    "        # y in (B, N)\n",
    "        B = y.size(0)\n",
    "        W = self.scale_W(adj, S)\n",
    "\n",
    "        # E-step\n",
    "        x = self.E_step(y, W)\n",
    "        # recompute graph\n",
    "        adj = self.glm(x) # unregularized adjacency\n",
    "        W = self.scale_W(adj, S)  # element-wise product to enforce sparsity pattern\n",
    "        L = torch.diag(W.sum(1)) - W\n",
    "        print(f'after E-step: delta_W norm {torch.norm(W - adj_learned):.4f}, GLR {GLR(x, L):.4f}')\n",
    "\n",
    "        # M-step-1: minimize GLR\n",
    "        self.M_step_1(x, L) # update parameters in glm\n",
    "        adj = self.glm(x) # unregularized adjacency\n",
    "        W = self.scale_W(adj, S)  # element-wise product to enforce sparsity pattern\n",
    "        L = torch.diag(W.sum(1)) - W\n",
    "        print(f'after M-step-1: delta_W norm {torch.norm(W - adj_learned):.4f}, GLR {GLR(x, L):.4f}')\n",
    "\n",
    "        # M-step-2: optimizing alpha with gradient steps\n",
    "        S = self.M_step_2(x, W)\n",
    "        return x, adj, S\n",
    "    \n",
    "    def forward(self, y, adj_init, S_init, num_iters=10):\n",
    "        adj = adj_init\n",
    "        S = S_init\n",
    "        \n",
    "        for it in range(num_iters):\n",
    "            print(f'Iteration {it+1}/{num_iters}')\n",
    "            x, adj, S = self.single_step(y, adj, S)\n",
    "            W = adj * S\n",
    "            draw_graph_from_adj(W.detach().cpu(), title=f'Learned Graph at Iteration {it+1}')\n",
    "        return x, adj, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae8aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
